\begin{answer}

(i)

Given $J(\theta) = \frac{1}{2}\beta\theta^2$, then $\nabla J(\theta) = \beta \theta$

then 
\begin{equation}
    \theta^{[t]} = \theta^{[t-1]} - \alpha\nabla J(\theta^{[t-1]}) = \theta^{[t-1]} - \alpha \beta \theta^{[t-1]} = (1 - \alpha \beta)\theta^{[t-1]} = \cdots = (1 - \alpha \beta) ^ t \theta ^{[0]}
\end{equation}


To make GD converges, $|1 - \alpha \beta| < 1$. Given $\beta > 0$,  we can derive the range of $\alpha$
\begin{equation*}
	0 < \alpha < \frac{2}{\beta}
\end{equation*}

When GD converges, given $|1 - \alpha \beta| < 1$, we have 

\begin{equation*}
	\theta^\dagger = \lim_{t\to\infty} (1 - \alpha \beta) ^ t \theta ^{[0]} = 0
\end{equation*}

Meanwhile, the global minimum $\theta^*$ satisfies $\nabla J(\theta^*) = \beta \theta^* = 0$

So 

\begin{equation*}
	\theta^* = \theta ^ \dagger = 0
\end{equation*}


(ii)

Given $\theta^{[t]} = (1 - \alpha \beta) ^ t \theta ^{[0]}$ and $\theta ^* = 0$, $|\theta^{[T]} - \theta^*| \le \epsilon$ is equivalent to

\begin{equation*}
	 (1 - \alpha \beta) ^ T \le \frac{\epsilon}{|\theta ^{[0]}|}
\end{equation*}

% then (for analysis simplicity we assume $ 0 < 1-\alpha\beta < 1$)
% \begin{equation*}
%     T*log(1- \alpha\beta) \le log(\frac{\epsilon}{|\theta ^{[0]}|})
% \end{equation*}
Discussion of how $\alpha$ impacts the T. 

Case 1

$ 0 < 1-\alpha\beta < 1$, we can get T by the following

\begin{equation*}
	 T \ge \frac{log(\frac{\epsilon}{|\theta ^{[0]}|})}{log(1- \alpha\beta)} 
\end{equation*}

When $\alpha$ increases, $|log(1- \alpha\beta)|$ increases and T decreases. 
When $\alpha$ is too small, $log(1 - \alpha\beta)$ gets closer to 0, causing the GD take longer to converge.

Case 2 

$ -1 < 1-\alpha\beta < 0$, when $\alpha$ is too significant. Under such case $(1 - \alpha\beta)^\top$ can flip between positive and negative and change in each iteration remains significant. When this happens,  it can prevent the algorithm from settling into a stable value. Since $(1 - \alpha \beta) ^ T \le \frac{\epsilon}{|\theta ^{[0]}|}$ doesn't necessarily means the GD has converged

When we can say GD converges, T needs to be 
\begin{equation*}
    T*log(|1- \alpha\beta|) \le log(\frac{\epsilon}{|\theta ^{[0]}|})
\end{equation*}

\begin{equation*}
	 T \ge \frac{log(\frac{\epsilon}{|\theta ^{[0]}|})}{log(|1- \alpha\beta|)} 
\end{equation*}

\end{answer}
