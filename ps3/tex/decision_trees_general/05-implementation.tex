\item \subquestionpoints{15} Now let's implement a classification, univariate decision tree with misclassification loss (mentioned in equation \ref{misclassificationloss}). The starter code is provided in \url{src/decision_trees_general/decision_tree.py}. Fill in the functions marked with \textbf{\#TODO}. You are not allowed to use any package other than NumPy. You \textbf{cannot} assume there are only two classes. \textbf{Deliverables}: report the accuracy output when running the Python script. For reference, the staff solution gives the same expected accuracy in part (a) for the college degree dataset (Table \ref{tab:decisionTree}) and 93.33\% for the iris dataset.